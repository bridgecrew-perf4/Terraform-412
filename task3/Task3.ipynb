{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwCJDlDblbfn"
      },
      "source": [
        "### Trying to solve Task 3 now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6lhwcGEQjLl"
      },
      "source": [
        "Prepare for Euler, i.e. logging stdout and stderr to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fd-6fxxQlZE"
      },
      "source": [
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "class Tee(object):\n",
        "    def __init__(self, *files):\n",
        "        self.files = files\n",
        "    def write(self, obj):\n",
        "        for f in self.files:\n",
        "            f.write(obj)\n",
        "            f.flush() # If you want the output to be visible immediately\n",
        "    def flush(self) :\n",
        "        for f in self.files:\n",
        "            f.flush()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzTzdbEwQr1B",
        "outputId": "bb2a4a39-55b8-4150-f963-9ab67ba1c94e"
      },
      "source": [
        "logfile = open('logAllFD.log', 'a')\n",
        "\n",
        "original_stderr = sys.stderr\n",
        "original_stdout = sys.stdout\n",
        "\n",
        "sys.stdout = Tee(sys.stdout, logfile)\n",
        "sys.stderr = sys.stdout\n",
        "\n",
        "print(f\"Starting new run at {datetime.now()}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new run at 2021-05-12 18:02:33.770662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDmyBvhoUAvS",
        "outputId": "f678648e-e956-4037-b453-95c3fa73eda5"
      },
      "source": [
        "!pip uninstall scikit-learn yellowbrick imbalanced-learn fancyimpute -y"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scikit-learn-0.21.3:\n",
            "  Successfully uninstalled scikit-learn-0.21.3\n",
            "\u001b[33mWARNING: Skipping yellowbrick as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping imbalanced-learn as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping fancyimpute as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6jANBlTrKL",
        "outputId": "1fa0aedc-c8aa-4cad-b1c4-f81353b41323"
      },
      "source": [
        "!pip install scikit-learn==0.21.3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.21.3\n",
            "  Using cached https://files.pythonhosted.org/packages/9f/c5/e5267eb84994e9a92a2c6a6ee768514f255d036f3c8378acfa694e9f2c99/scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.19.5)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-0.21.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oehqk2wZPnlF"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import operator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Not sure if it would work on euler\n",
        "#trainUrl = 'https://raw.githubusercontent.com/Toroto006/iml2021/main/task3/train.csv?token=AH44KNUX4PZX2ZQVSNK7UFLATNZ64'\n",
        "#testUrl = 'https://raw.githubusercontent.com/Toroto006/iml2021/main/task3/test.csv?token=AH44KNVTLV33VIFDUBUKCTTATNZ6W'\n",
        "\n",
        "trainUrl = 'train.csv'\n",
        "testUrl = 'test.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeDrTMSzNizS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795aa8ff-ccd2-4605-f93f-6ae4b2fdeadc"
      },
      "source": [
        "trainPD = pd.read_csv(trainUrl)\n",
        "print(trainPD.head(3))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Sequence  Active\n",
            "0     DKWL       0\n",
            "1     FCHN       0\n",
            "2     KDQP       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKnAPAXjQcqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0a0582-4fe6-4bd3-fafd-83cbdc3b09b0"
      },
      "source": [
        "testPD = pd.read_csv(testUrl)\n",
        "print(testPD.head(3))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Sequence\n",
            "0     HWFK\n",
            "1     MWPW\n",
            "2     ALDV\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcZfeKc5Nnbe"
      },
      "source": [
        "Let's first take a more thorough look at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nXsql9cdjsY",
        "outputId": "2b1cff82-9f77-4585-b011-1d56eda806f1"
      },
      "source": [
        "aminoAcids = {\n",
        "    \"R\" : 1,\n",
        "    \"H\" : 2,\n",
        "    \"K\" : 3,\n",
        "    \"D\" : 4,\n",
        "    \"E\" : 5,\n",
        "    \"S\" : 6,\n",
        "    \"T\" : 7,\n",
        "    \"N\" : 8,\n",
        "    \"Q\" : 9,\n",
        "    \"C\" : 10,\n",
        "    \"U\" : 11,\n",
        "    \"G\" : 12,\n",
        "    \"P\" : 13,\n",
        "    \"A\" : 14,\n",
        "    \"I\" : 15,\n",
        "    \"L\" : 16,\n",
        "    \"M\" : 17,\n",
        "    \"F\" : 18,\n",
        "    \"W\" : 19,\n",
        "    \"Y\" : 20,\n",
        "    \"V\" : 21,\n",
        "}\n",
        "\n",
        "def really_safe_normalise_in_place(d):\n",
        "    factor=1.0/math.fsum(d.values())\n",
        "    for k in d:\n",
        "        d[k] = d[k]*factor\n",
        "    key_for_max = max(d.items(), key=operator.itemgetter(1))[0]\n",
        "    diff = 1.0 - math.fsum(d.values())\n",
        "    #print \"discrepancy = \" + str(diff)\n",
        "    d[key_for_max] += diff\n",
        "    return d\n",
        "\n",
        "#aminoAcids = really_safe_normalise_in_place(aminoAcids)\n",
        "aminoAcids[\"D\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzvbAkXWvNFf"
      },
      "source": [
        "permutations= []\n",
        "for elm1 in aminoAcids:\n",
        "  for elm2 in aminoAcids:\n",
        "    for elm3 in aminoAcids: \n",
        "      for elm4 in aminoAcids:\n",
        "        permutations.append(elm1+elm2+elm3+elm4)\n",
        "\n",
        "#print(permutations)\n",
        "permutDF = pd.DataFrame(permutations, columns = ['Permutations'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIv-q9shOr9f"
      },
      "source": [
        "splitNames = [\"fir\", \"sec\", \"thr\", \"for\"]\n",
        "\n",
        "def splitPlaces(dfs, enc=None):\n",
        "  def lmdFct(df):\n",
        "    return pd.Series(list(df[\"Sequence\"]))\n",
        "  #splits = dfs.apply(lambda df: [aminoAcids.get(item,item) for item in list(df[\"Sequence\"])], axis=1, result_type='expand').rename(columns={0:\"fir\", 1:\"sec\", 2:\"thr\", 3:\"for\"})\n",
        "  splits = dfs.apply(lmdFct, axis=1, result_type='expand').rename(columns={0:\"fir\", 1:\"sec\", 2:\"thr\", 3:\"for\"})\n",
        "  #print(splits.shape)\n",
        "  if enc is None:\n",
        "    def lmdFct2(df):\n",
        "      return pd.Series(list(df[\"Permutations\"]))\n",
        "    enc = OneHotEncoder()\n",
        "    temp= permutDF.apply(lmdFct2, axis=1, result_type='expand').rename(columns={0:\"fir\", 1:\"sec\", 2:\"thr\", 3:\"for\"})\n",
        "    enc.fit(temp)\n",
        "  onehotlabels = enc.transform(splits).toarray()\n",
        "  #print(onehotlabels.shape)\n",
        "  new_dfs = dfs.copy()\n",
        "  #print(enc.get_feature_names())\n",
        "  for ind in list(enc.get_feature_names()):\n",
        "    new_dfs[ind] = 0\n",
        "  new_dfs[enc.get_feature_names()] = onehotlabels\n",
        "  return new_dfs, enc\n",
        "\n",
        "splitPD, enc = splitPlaces(trainPD.head(15))\n",
        "\n",
        "#print(splitPD.head(5))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fttbyqp-gceN"
      },
      "source": [
        "To try the idea do train and test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Ixu1v_akIL"
      },
      "source": [
        "random_state = 42\n",
        "# split labels\n",
        "def createTrainSplit():\n",
        "  Xs = splitPD.drop(\"Sequence\", axis='columns')\n",
        "  train_split, test_split = train_test_split(Xs, test_size=0.2, random_state=random_state)\n",
        "  train_y = train_split[\"Active\"]\n",
        "  train_X = train_split.drop(\"Active\", axis='columns')\n",
        "  test_y = test_split[\"Active\"]\n",
        "  test_X = test_split.drop(\"Active\", axis='columns')\n",
        "  print(train_X.head(5))\n",
        "  print(train_y.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAH_fsn6giG2"
      },
      "source": [
        "Lets try a RidgeClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvS0Ata1glUq"
      },
      "source": [
        "def normalSVC():\n",
        "  svcInit = SVC(class_weight='balanced', random_state=random_state)\n",
        "  svc = svcInit.fit(train_X, train_y)\n",
        "  train_predicted = svc.predict(train_X)\n",
        "  test_predicted = svc.predict(test_X)\n",
        "  print(f\"train score: {f1_score(train_y, train_predicted)}\") # 0.855\n",
        "  print(f\"test score: {f1_score(test_y, test_predicted)}\") # 0.805\n",
        "\n",
        "# normalSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPXBdWbCuRH3"
      },
      "source": [
        "Looks quite good, lets do a gridsearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w66ScJH7UO8j"
      },
      "source": [
        "def findBest():\n",
        "  parameters = {'kernel':('linear', 'poly', 'rbf'), 'C':[1, 10]}\n",
        "  clf = GridSearchCV(svcInit, parameters)\n",
        "  clf = clf.fit(train_X, train_y)\n",
        "  train_predicted = clf.predict(train_X)\n",
        "  test_predicted = clf.predict(test_X)\n",
        "  print(f\"train score: {f1_score(train_y, train_predicted)}\") # 0.99229\n",
        "  print(f\"test score: {f1_score(test_y, test_predicted)}\") # 0.88872\n",
        "  print(clf.get_params()['estimator'])\n",
        "  # SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
        "  # decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "  # max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
        "  # verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnPqb273SibC"
      },
      "source": [
        "Wow, looks good!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RotowDbqW_Vo"
      },
      "source": [
        "enc = None\n",
        "def loadOneHotEncodingJoblib():\n",
        "  from joblib import load\n",
        "  enc = load('encoder.joblib')\n",
        "#loadOneHotEncodingJoblib()\n",
        "\n",
        "def loadOneHotEncodingPickle():\n",
        "  import pickle\n",
        "  with open('encoder.pickle', 'rb') as f:\n",
        "    enc = pickle.load(f)\n",
        "#loadOneHotEncodingPickle()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lozqFgL4U6Hq"
      },
      "source": [
        "X, _ = splitPlaces(trainPD, enc)\n",
        "y = X[\"Active\"]\n",
        "X = X.drop([\"Sequence\", \"Active\"], axis='columns')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7vzTISOW2Sr"
      },
      "source": [
        "def saveOneHotEncoding():\n",
        "  from joblib import dump\n",
        "  dump(enc, 'encoder.joblib')\n",
        "#saveOneHotEncoding()\n",
        "\n",
        "def dumpOneHotEncodingPickle():\n",
        "  import pickle\n",
        "  with open('encoder.pickle', 'wb') as f:\n",
        "      pickle.dump(enc, f)\n",
        "dumpOneHotEncodingPickle()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-yttGg5Sntc"
      },
      "source": [
        "testedClf = SVC(C=1.0, cache_size=2000, class_weight='balanced', coef0=0.0,\n",
        "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
        "     max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
        "     verbose=False)\n",
        "#testedClf = testedClf.fit(X, y)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kd-qYC-TCxu"
      },
      "source": [
        "Prepare submission data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsKJpgyqTErX"
      },
      "source": [
        "test_Xs, _ = splitPlaces(testPD, enc)\n",
        "testXs = test_Xs.drop(\"Sequence\", axis='columns')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-wvxWWGTacF"
      },
      "source": [
        "def doSVCpredict():\n",
        "  submission_predicted = testedClf.predict(testXs)\n",
        "  submission_predicted = pd.DataFrame(submission_predicted, columns=[\"Active\"])\n",
        "  return submission_predicted\n",
        "\n",
        "#submission_predicted = doSVCpredict()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUCiIOM-MxXo"
      },
      "source": [
        "Lets try an MLPClassifier again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOaB9Yp3Mx3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "87d55e26-a936-4802-8198-58d34f9e4410"
      },
      "source": [
        "parameters={\n",
        "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
        "'hidden_layer_sizes': [x for x in product(range(10,100,5), range(1,10,2))],\n",
        "'alpha': 10.0 ** -np.arange(1, 7),\n",
        "'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
        "}\n",
        "\n",
        "def eulerGrid(parameters):\n",
        "  print(\"Starting to fit over grid search\")\n",
        "\n",
        "  clfMLPCgrid = GridSearchCV(estimator=MLPClassifier(solver='lbfgs', random_state=random_state),param_grid=parameters,n_jobs=-1,verbose=2,cv=10)\n",
        "  print(clfMLPCgrid.fit(X, y))\n",
        "\n",
        "  submission_predicted = clfMLPCgrid.predict(testXs)\n",
        "  submission_predicted = pd.DataFrame(submission_predicted, columns=[\"Active\"])\n",
        "  return submission_predicted\n",
        "\n",
        "submission_predicted = eulerGrid(parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cb22bf51eeb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0mclfMLPCgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfMLPCgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqp1UMkZM0_k"
      },
      "source": [
        "def testPredict():\n",
        "  train_predicted = clfMLPCgrid.predict(train_X)\n",
        "  test_predicted = clfMLPCgrid.predict(test_X)\n",
        "  print(f\"train score: {f1_score(train_y, train_predicted)}\")\n",
        "  print(f\"test score: {f1_score(test_y, test_predicted)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCpg6ZjdQzkc"
      },
      "source": [
        "sys.stdout = original_stdout\n",
        "sys.stderr = original_stderr\n",
        "logfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbEvR0Kj0mGA"
      },
      "source": [
        "def defaultMLPC():\n",
        "  clf = MLPClassifier(random_state=1, max_iter=300).fit(X, y)\n",
        "  submission_predicted = clf.predict(testXs)\n",
        "  submission_predicted = pd.DataFrame(submission_predicted, columns=[\"Active\"])\n",
        "  return submission_predicted\n",
        "\n",
        "#submission_predicted = defaultMLPC()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvyuMd0XbWu6"
      },
      "source": [
        "submission_predicted.to_csv(\"testOutEuler.csv\", index=False, header=False)"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}